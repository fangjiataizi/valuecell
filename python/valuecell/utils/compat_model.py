"""
LLM æ¨¡å‹å…¼å®¹å±‚

ä¸ºä¸æ”¯æŒ 'developer' è§’è‰²çš„ LLM æä¾›å•†ï¼ˆå¦‚ Qwenã€DeepSeekï¼‰æä¾›å…¼å®¹æ€§æ”¯æŒã€‚
é€šè¿‡æ¶ˆæ¯æ‹¦æˆªå’Œè§’è‰²è½¬æ¢ï¼Œä½¿å…¶èƒ½å¤Ÿä¸ Agno æ¡†æ¶æ­£å¸¸å·¥ä½œã€‚
"""

import os
from typing import Any, Dict, List, Optional
import functools

from agno.models.base import Model
from agno.models.google import Gemini
from agno.models.openai import OpenAIChat
from agno.models.openrouter import OpenRouter

# å…¨å±€æ ‡å¿—ï¼Œç¡®ä¿åª monkey patch ä¸€æ¬¡
_GLOBAL_PATCHED = False


class CompatibleOpenAIChat(OpenAIChat):
    """
    å…¼å®¹ Qwen å’Œ DeepSeek çš„ OpenAI Chat æ¨¡å‹åŒ…è£…å™¨
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. å°† 'developer' è§’è‰²è½¬æ¢ä¸º 'system' è§’è‰²
    2. åˆå¹¶è¿ç»­çš„ system æ¶ˆæ¯ä»¥ç¬¦åˆ API è¦æ±‚
    """
    
    def __init__(self, *args, role_mapping: Optional[Dict[str, str]] = None, **kwargs):
        """
        åˆå§‹åŒ–å…¼å®¹çš„ OpenAI Chat æ¨¡å‹
        
        Args:
            role_mapping: è§’è‰²æ˜ å°„å­—å…¸ï¼Œä¾‹å¦‚ {"developer": "system"}
            å…¶ä»–å‚æ•°ä¼ é€’ç»™çˆ¶ç±»
        """
        super().__init__(*args, **kwargs)
        self.role_mapping = role_mapping or {"developer": "system"}
        
        # è¦†ç›– role_map
        # Agno é»˜è®¤å°† 'system' æ˜ å°„ä¸º 'developer'ï¼Œä½†é€šä¹‰åƒé—®ä¸æ”¯æŒ developer
        # æˆ‘ä»¬éœ€è¦å®Œæ•´è¦†ç›– role_mapï¼Œä¿æŒ system -> system
        self.role_map = {
            'system': 'system',      # ä¸è¦æ˜ å°„ä¸º developer
            'user': 'user',
            'assistant': 'assistant',
            'tool': 'tool',
            'model': 'assistant',
            'developer': 'system',   # é˜²å¾¡æ€§ï¼šå¦‚æœè¿˜æœ‰ developer å°±æ˜ å°„ä¸º system
        }
        
        import logging
        logger = logging.getLogger(__name__)
        logger.info("ğŸ [CompatModel] æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œrole_map å·²è®¾ç½®")
        
        # ç«‹å³è¿›è¡Œå…¨å±€ monkey patchï¼ˆåªåšä¸€æ¬¡ï¼‰
        self._apply_global_patch()
    
    def _apply_global_patch(self):
        """åœ¨ OpenAI ç±»çº§åˆ«åº”ç”¨ monkey patchï¼Œç¡®ä¿æ‰€æœ‰å®ä¾‹éƒ½è¢«æ‹¦æˆª"""
        global _GLOBAL_PATCHED
        
        if _GLOBAL_PATCHED:
            return
        
        import logging
        logger = logging.getLogger(__name__)
        logger.info("ğŸ”§ [CompatModel] å¼€å§‹å…¨å±€ monkey patch OpenAI client")
        
        try:
            from openai import OpenAI
            
            # ä¿å­˜åŸå§‹çš„ __init__ æ–¹æ³•
            original_init = OpenAI.__init__
            
            # åˆ›å»ºåŒ…è£…çš„ __init__
            def wrapped_init(client_self, *args, **kwargs):
                # è°ƒç”¨åŸå§‹ __init__
                original_init(client_self, *args, **kwargs)
                
                # åŒ…è£… chat.completions.create
                if hasattr(client_self, 'chat') and hasattr(client_self.chat, 'completions'):
                    original_create = client_self.chat.completions.create
                    
                    @functools.wraps(original_create)
                    def create_wrapper(*create_args, **create_kwargs):
                        # è½¬æ¢æ¶ˆæ¯ä¸­çš„ developer è§’è‰²
                        if 'messages' in create_kwargs and create_kwargs['messages']:
                            messages = create_kwargs['messages']
                            for msg in messages:
                                if isinstance(msg, dict) and msg.get('role') == 'developer':
                                    msg['role'] = 'system'
                                    logger.info(f"âœ… [GlobalPatch] è§’è‰²è½¬æ¢: developer -> system")
                        
                        # å¤„ç†é€šä¹‰åƒé—®çš„ response_format é™åˆ¶
                        # å½“ä½¿ç”¨ json_object æ ¼å¼æ—¶ï¼Œå¿…é¡»åœ¨ messages ä¸­åŒ…å« "json" å­—æ ·
                        if 'response_format' in create_kwargs:
                            response_format = create_kwargs.get('response_format')
                            logger.info(f"ğŸ” [GlobalPatch] æ£€æµ‹åˆ° response_format: {response_format}, ç±»å‹: {type(response_format)}")
                            
                            # æ£€æŸ¥æ˜¯å¦ä¸º JSON ç›¸å…³æ ¼å¼ï¼ˆjson_object æˆ– json_schemaï¼‰
                            is_json_format = False
                            format_type = None
                            if isinstance(response_format, dict):
                                format_type = response_format.get('type')
                                if format_type in ['json_object', 'json_schema']:
                                    is_json_format = True
                                    logger.info(f"ğŸ” [GlobalPatch] è¯†åˆ«ä¸º {format_type} (dict)")
                            elif hasattr(response_format, 'type'):
                                format_type = getattr(response_format, 'type', None)
                                if format_type in ['json_object', 'json_schema']:
                                    is_json_format = True
                                    logger.info(f"ğŸ” [GlobalPatch] è¯†åˆ«ä¸º {format_type} (object)")
                            
                            if is_json_format:
                                messages = create_kwargs.get('messages', [])
                                logger.info(f"ğŸ” [GlobalPatch] json_object æ ¼å¼ï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
                                
                                if messages:
                                    logger.info(f"ğŸ” [GlobalPatch] æœ€åä¸€æ¡æ¶ˆæ¯è§’è‰²: {messages[-1].get('role') if isinstance(messages[-1], dict) else 'unknown'}")
                                
                                # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å« "json" å­—æ ·ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                                has_json_keyword = False
                                for i, msg in enumerate(messages):
                                    if isinstance(msg, dict):
                                        content = str(msg.get('content', '')).lower()
                                        if 'json' in content:
                                            has_json_keyword = True
                                            logger.info(f"ğŸ” [GlobalPatch] åœ¨æ¶ˆæ¯ {i} ä¸­å‘ç° JSON å…³é”®å­—")
                                            break
                                
                                logger.info(f"ğŸ” [GlobalPatch] æ˜¯å¦å·²åŒ…å« JSON å…³é”®å­—: {has_json_keyword}")
                                
                                # å¦‚æœæ²¡æœ‰ï¼Œåœ¨æœ€åä¸€æ¡æ¶ˆæ¯ä¸­æ·»åŠ æç¤º
                                if not has_json_keyword and messages:
                                    last_msg = messages[-1]
                                    last_role = last_msg.get('role') if isinstance(last_msg, dict) else None
                                    logger.info(f"ğŸ” [GlobalPatch] å‡†å¤‡ä¿®æ”¹æœ€åä¸€æ¡æ¶ˆæ¯ï¼Œè§’è‰²: {last_role}")
                                    
                                    if isinstance(last_msg, dict):
                                        original_content = last_msg.get('content', '')
                                        last_msg['content'] = f"{original_content}\n\nPlease respond in JSON format."
                                        logger.info(f"âœ… [GlobalPatch] ä¸º json_object å“åº”æ ¼å¼æ·»åŠ  JSON å…³é”®å­—æç¤º (è§’è‰²: {last_role})")
                                    else:
                                        logger.warning(f"[GlobalPatch] æœ€åä¸€æ¡æ¶ˆæ¯ä¸æ˜¯å­—å…¸: {type(last_msg)}")
                        
                        return original_create(*create_args, **create_kwargs)
                    
                    client_self.chat.completions.create = create_wrapper
            
            # æ›¿æ¢ __init__
            OpenAI.__init__ = wrapped_init
            _GLOBAL_PATCHED = True
            logger.info("âœ… [CompatModel] å…¨å±€ monkey patch å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ [CompatModel] å…¨å±€ monkey patch å¤±è´¥: {e}")
    
    def get_client(self):
        """
        è·å– clientï¼ˆå·²ç»è¢«å…¨å±€ patch å¤„ç†è¿‡äº†ï¼‰
        """
        return super().get_client()
    
    def _transform_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        è½¬æ¢æ¶ˆæ¯åˆ—è¡¨ï¼Œå¤„ç†ä¸å…¼å®¹çš„è§’è‰²
        
        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            è½¬æ¢åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if not messages:
            return messages
        
        import logging
        logger = logging.getLogger(__name__)
        
        # è®°å½•åŸå§‹æ¶ˆæ¯çš„è§’è‰²
        original_roles = [msg.get("role") if isinstance(msg, dict) else "?" for msg in messages[:3]]
        logger.info(f"ğŸ”„ [CompatModel] å¼€å§‹è½¬æ¢æ¶ˆæ¯ï¼Œå‰3ä¸ªè§’è‰²: {original_roles}")
        
        transformed = []
        
        for msg in messages:
            if not isinstance(msg, dict):
                transformed.append(msg)
                continue
            
            # å¤åˆ¶æ¶ˆæ¯ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            new_msg = dict(msg)
            
            # åº”ç”¨è§’è‰²æ˜ å°„
            if "role" in new_msg and new_msg["role"] in self.role_mapping:
                old_role = new_msg["role"]
                new_msg["role"] = self.role_mapping[old_role]
                logger.info(f"âœ… [CompatModel] è§’è‰²è½¬æ¢: {old_role} -> {new_msg['role']}")
            
            transformed.append(new_msg)
        
        # åˆå¹¶è¿ç»­çš„ system æ¶ˆæ¯ï¼ˆæŸäº› API ä¸å…è®¸å¤šä¸ªè¿ç»­çš„ system æ¶ˆæ¯ï¼‰
        transformed = self._merge_system_messages(transformed)
        
        # è®°å½•è½¬æ¢åçš„è§’è‰²
        final_roles = [msg.get("role") if isinstance(msg, dict) else "?" for msg in transformed[:3]]
        logger.info(f"âœ… [CompatModel] è½¬æ¢å®Œæˆï¼Œå‰3ä¸ªè§’è‰²: {final_roles}")
        
        return transformed
    
    def _merge_system_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶è¿ç»­çš„ system æ¶ˆæ¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if not messages:
            return messages
        
        merged = []
        system_buffer = []
        
        for msg in messages:
            if not isinstance(msg, dict):
                if system_buffer:
                    merged.append(self._create_merged_system_message(system_buffer))
                    system_buffer = []
                merged.append(msg)
                continue
            
            if msg.get("role") == "system":
                system_buffer.append(msg)
            else:
                if system_buffer:
                    merged.append(self._create_merged_system_message(system_buffer))
                    system_buffer = []
                merged.append(msg)
        
        # å¤„ç†æœ«å°¾çš„ system æ¶ˆæ¯
        if system_buffer:
            merged.append(self._create_merged_system_message(system_buffer))
        
        return merged
    
    def _create_merged_system_message(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        å°†å¤šä¸ª system æ¶ˆæ¯åˆå¹¶ä¸ºä¸€ä¸ª
        
        Args:
            messages: system æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„å•ä¸ª system æ¶ˆæ¯
        """
        if len(messages) == 1:
            return messages[0]
        
        # åˆå¹¶æ‰€æœ‰ system æ¶ˆæ¯çš„å†…å®¹
        contents = []
        for msg in messages:
            content = msg.get("content", "")
            if content:
                contents.append(content)
        
        merged_content = "\n\n".join(contents)
        
        return {
            "role": "system",
            "content": merged_content
        }


def create_qwen_model(model_id: str = "qwen-plus", api_key: Optional[str] = None) -> CompatibleOpenAIChat:
    """
    åˆ›å»ºå…¼å®¹çš„ Qwen æ¨¡å‹å®ä¾‹
    
    Args:
        model_id: æ¨¡å‹ IDï¼Œä¾‹å¦‚ "qwen-plus", "qwen-turbo", "qwen-max"
        api_key: DashScope API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        
    Returns:
        å…¼å®¹çš„ OpenAI Chat æ¨¡å‹å®ä¾‹
    """
    api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("DASHSCOPE_API_KEY is required for Qwen models")
    
    model = CompatibleOpenAIChat(
        id=model_id,
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        role_mapping={"developer": "system"},  # Qwen ä¸æ”¯æŒ developer è§’è‰²
    )
    
    # ç¡®ä¿åœ¨å½“å‰è¿›ç¨‹ä¸­åº”ç”¨å…¨å±€ patchï¼ˆå› ä¸ºå¯èƒ½æ˜¯æ–°è¿›ç¨‹ï¼‰
    model._apply_global_patch()
    
    return model


def create_deepseek_model(model_id: str = "deepseek-chat", api_key: Optional[str] = None) -> CompatibleOpenAIChat:
    """
    åˆ›å»ºå…¼å®¹çš„ DeepSeek æ¨¡å‹å®ä¾‹
    
    Args:
        model_id: æ¨¡å‹ IDï¼Œä¾‹å¦‚ "deepseek-chat", "deepseek-coder"
        api_key: DeepSeek API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        
    Returns:
        å…¼å®¹çš„ OpenAI Chat æ¨¡å‹å®ä¾‹
    """
    api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError("DEEPSEEK_API_KEY is required for DeepSeek models")
    
    return CompatibleOpenAIChat(
        id=model_id,
        api_key=api_key,
        base_url="https://api.deepseek.com",
        role_mapping={"developer": "system"},  # DeepSeek ä¸æ”¯æŒ developer è§’è‰²
    )

